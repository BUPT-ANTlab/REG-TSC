# -- coding: utf-8 --
import os
import numpy as np
from volcenginesdkarkruntime import Ark
from typing import List, Optional

# ä»ç¯å¢ƒå˜é‡ä¸­è·å–API Keyï¼Œè¿™æ˜¯æ¨èçš„å®‰å…¨å®è·µ
api_key = ""# add a key
if not api_key:
    raise ValueError("è¯·è®¾ç½®ç¯å¢ƒå˜é‡ ARK_API_KEY")

print("å®¢æˆ·ç«¯åˆå§‹åŒ–...")
client = Ark(api_key=api_key)
print("å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸï¼")

# æˆ‘ä»¬å°†ä½¿ç”¨è¿™ä¸ªå‡½æ•°æ¥å¤„ç†æ–‡æ¡£å’ŒæŸ¥è¯¢
def get_embeddings(
        texts: List[str],
        is_query: bool = False,
        mrl_dim: Optional[int] = 1024
) -> np.ndarray:
    """
    è°ƒç”¨è±†åŒ…æ¨¡å‹å°†æ–‡æœ¬åˆ—è¡¨è½¬æ¢ä¸ºå‘é‡
    """
    # å¯¹äºæŸ¥è¯¢ï¼Œæ¨¡å‹æ¨èæ·»åŠ ç‰¹å®šæŒ‡ä»¤ä»¥è·å¾—æœ€ä½³æ£€ç´¢æ€§èƒ½
    if is_query:
        inputs = [f"Instruct: Given a web search query, retrieve relevant passages that answer the query\nQuery: {text}"
                  for text in texts]
    else:
        inputs = texts

    # è°ƒç”¨API
    resp = client.embeddings.create(
        model="doubao-embedding-large-text-250515",
        input=inputs,
        encoding_format="float",
    )

    # ä»å“åº”ä¸­æå–å‘é‡
    embedding_list = [d.embedding for d in resp.data]
    embedding_array = np.array(embedding_list, dtype=np.float32)

    # å¦‚æœæŒ‡å®šäº†MRLç»´åº¦ï¼Œåˆ™è¿›è¡Œæˆªæ–­
    if mrl_dim is not None:
        assert mrl_dim in [2048, 1024, 512, 256], "æ”¯æŒçš„MRLç»´åº¦ä¸º 2048, 1024, 512, 256"
        embedding_array = embedding_array[:, :mrl_dim]

    # **å…³é”®æ­¥éª¤ï¼šå½’ä¸€åŒ–**
    # å½’ä¸€åŒ–åï¼Œå‘é‡çš„æ¨¡é•¿ä¸º1ï¼Œè¿™æ ·è®¡ç®—ç‚¹ç§¯å°±ç­‰åŒäºè®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦ï¼Œéå¸¸é«˜æ•ˆã€‚
    norm = np.linalg.norm(embedding_array, axis=1, keepdims=True)
    normalized_embeddings = embedding_array / norm

    return normalized_embeddings


# --- 3. é˜¶æ®µä¸€ï¼šå»ºç«‹çŸ¥è¯†åº“ç´¢å¼• ---
print("\n--- é˜¶æ®µä¸€ï¼šå»ºç«‹çŸ¥è¯†åº“ç´¢å¼• ---")

# è¿™æ˜¯æˆ‘ä»¬çš„â€œçŸ¥è¯†åº“â€ï¼ŒåŒ…å«å‡ æ®µå…³äºå¤ªé˜³ç³»è¡Œæ˜Ÿçš„æè¿°
documents = [
    "åœ°çƒæ˜¯å¤ªé˜³ç³»ä¸­ä»å†…åˆ°å¤–çš„ç¬¬ä¸‰é¢—è¡Œæ˜Ÿï¼Œä¹Ÿæ˜¯äººç±»å·²çŸ¥çš„å”¯ä¸€å­•è‚²ç”Ÿå‘½çš„å¤©ä½“ã€‚å®ƒæ‹¥æœ‰ä¸°å¯Œçš„æ°´èµ„æºå’Œå¤šæ ·åŒ–çš„ç”Ÿæ€ç³»ç»Ÿã€‚",
    "ç«æ˜Ÿæ˜¯å¤ªé˜³ç³»çš„ç¬¬å››é¢—è¡Œæ˜Ÿï¼Œå› å…¶è¡¨é¢å¯Œå«æ°§åŒ–é“è€Œå‘ˆç°å‡ºç‹¬ç‰¹çš„çº¢è‰²å¤–è§‚ã€‚ç§‘å­¦å®¶ä»¬ä¸€ç›´åœ¨æ¢ç´¢ç«æ˜Ÿä¸Šæ˜¯å¦å­˜åœ¨è¿‡ç”Ÿå‘½ã€‚",
    "æœ¨æ˜Ÿæ˜¯å¤ªé˜³ç³»ä¸­ä½“ç§¯æœ€å¤§ã€è´¨é‡æœ€é‡çš„è¡Œæ˜Ÿï¼Œæ˜¯ä¸€é¢—å·¨å¤§çš„æ°”æ€å·¨è¡Œæ˜Ÿã€‚å®ƒæœ‰ç€è‘—åçš„å¤§çº¢æ–‘ï¼Œä¸€ä¸ªæŒç»­äº†æ•°ç™¾å¹´çš„å·¨å¤§é£æš´ã€‚",
    "åœŸæ˜Ÿä»¥å…¶å£®è§‚çš„è¡Œæ˜Ÿç¯è€Œé—»åï¼Œè¿™äº›ç¯ä¸»è¦ç”±å†°å—å’Œå²©çŸ³é¢—ç²’ç»„æˆã€‚å®ƒæ˜¯å¤ªé˜³ç³»ä¸­çš„ç¬¬äºŒå¤§æ°”æ€å·¨è¡Œæ˜Ÿã€‚",
]
print("ğŸ“š çŸ¥è¯†åº“å†…å®¹ï¼š")
for i, doc in enumerate(documents):
    print(f"  [{i}] {doc}")

# æ³¨æ„ï¼šè¿™é‡Œ is_query=False
print("\nğŸ”„ æ­£åœ¨å°†æ–‡æ¡£è½¬æ¢ä¸ºå‘é‡...")
document_embeddings = get_embeddings(documents, is_query=False, mrl_dim=1024)
print(f"æˆåŠŸåˆ›å»ºäº† {document_embeddings.shape[0]} ä¸ªæ–‡æ¡£å‘é‡ï¼Œæ¯ä¸ªå‘é‡ç»´åº¦ä¸º {document_embeddings.shape[1]}ã€‚")

# --- 4. é˜¶æ®µäºŒï¼šå¤„ç†ç”¨æˆ·æŸ¥è¯¢å¹¶æ‰§è¡Œæ£€ç´¢ ---
print("\n--- é˜¶æ®µäºŒï¼šæ‰§è¡Œè¯­ä¹‰æ£€ç´¢ ---")

# ç”¨æˆ·çš„æŸ¥è¯¢
user_query = "å“ªé¢—è¡Œæ˜Ÿæ˜¯çº¢è‰²çš„ï¼Ÿ"
print(f"ç”¨æˆ·æŸ¥è¯¢: {user_query}")

# **æ³¨æ„ï¼šè¿™é‡Œ is_query=Trueï¼Œè¿™ä¼šè§¦å‘å‡½æ•°å†…éƒ¨æ·»åŠ æŒ‡ä»¤å‰ç¼€**
print("æ­£åœ¨å°†æŸ¥è¯¢è½¬æ¢ä¸ºå‘é‡...")
query_embedding = get_embeddings([user_query], is_query=True, mrl_dim=1024)
print("æŸ¥è¯¢å‘é‡åˆ›å»ºæˆåŠŸï¼")

# np.dot(A, B.T)
print("\nğŸ” æ­£åœ¨è®¡ç®—æŸ¥è¯¢ä¸æ‰€æœ‰æ–‡æ¡£çš„ç›¸ä¼¼åº¦...")
similarities = np.dot(document_embeddings, query_embedding.T)

best_doc_index = np.argmax(similarities)
similarity_score = similarities[best_doc_index][0]

print("\n---æ£€ç´¢ç»“æœ ---")
print(f"æœ€é«˜ç›¸ä¼¼åº¦åˆ†æ•°: {similarity_score:.4f}")
print(f"æœ€ç›¸å…³çš„æ–‡æ¡£ç´¢å¼•: {best_doc_index}")
print(f"ğŸ’¬ æœ€ç›¸å…³çš„æ–‡æ¡£å†…å®¹: \n  '{documents[best_doc_index]}'")

print("\n--- æ¼”ç¤ºç»“æŸ ---")